{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meditations with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan\n",
    "\n",
    "1. Create a plan\n",
    "1. Obtain the data\n",
    "1. Analyze the data\n",
    "1. Clean the data\n",
    "1. Prepare the data\n",
    "1. Create the LSTM model\n",
    "1. Train the model\n",
    "1. Use the model for predictions\n",
    "1. Create the Python module\n",
    "1. Bonus: setup your local machine for deep learning\n",
    "1. Bonus: setup AWS for deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare your environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to http://www.gutenberg.org/ebooks/2680\n",
    "# Download Plain Text UTF-8 version\n",
    "# Place it in the same directory as your Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the source file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './meditations.txt'\n",
    "raw_source_text = open(path).read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan the source file. What can cause problems while training our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_from = 'THE FIRST BOOK'\n",
    "end_at = 'APPENDIX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we have enought raw text for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_source_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index for the real start of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_source_text.find(start_from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's inspect what we are removing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_source_text[:raw_source_text.find(start_from)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index for the real end of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_source_text.find(end_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That didn't work. Let's try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_source_text.rfind(end_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_source_text[raw_source_text.rfind(end_at):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first 2000 characters of the real text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_source_text[raw_source_text.find(start_from):raw_source_text.find(start_from)+2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of everything before and after the real text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_text = raw_source_text[raw_source_text.find(start_from):raw_source_text.rfind(end_at)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first 1000 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the last 1000 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_text[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first problem, which we are going to solve is the book titles.\n",
    "# The Meditations consists of 12 books and all of them begin with 'THE XXXX BOOK'.\n",
    "# We don't want our model to learn this so we are going to remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `r` syntax variants for strings are very useful for regular expressions.\n",
    "# `r` strings treat all the characters literally.\n",
    "# There is no need need to escape slashes and other special characters.\n",
    "prepared_text = re.sub(r'THE\\s\\w+\\sBOOK\\n', '', prepared_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_text[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is another problem - chapter numbering.\n",
    "# Each book of The Meditations has numbered chapters.\n",
    "# Again, we don't want to train on this so let's remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_text = re.sub(r'\\n[XVI]+\\.\\s', '', prepared_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_text[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are not done yet: there are a lot of \\n and other special characters.\n",
    "# First, print a list of all the unique characters in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(sorted(list(set(prepared_text))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is a normal practice to convert all the text to lowercase to improve performance.\n",
    "# Let's do that right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_text = prepared_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the characters except the whitelisted ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_text = re.sub(r'[^\\,\\.\\!\\?\\'\\;\\:\\-a-z]+', ' ', prepared_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the list of unique characters again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(list(set(prepared_text))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sorted(list(set(prepared_text))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first 1000 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total length of the `prepared text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prepared_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the `prepared_text` to `text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = prepared_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare variables for things, which we are going to use a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chars = sorted(list(set(text)))\n",
    "vocabulary_size = len(unique_chars)\n",
    "char_to_index = {c: i for i, c in enumerate(unique_chars)}\n",
    "index_to_char = {i: c for i, c in enumerate(unique_chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide what sentence length and step we are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_length = 88\n",
    "step = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sentence -> next character pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text)-sentence_length, step):\n",
    "    sentences.append(text[i:i+sentence_length])\n",
    "    next_chars.append(text[i+sentence_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_shape = len(sentences), sentence_length, vocabulary_size\n",
    "y_shape = len(sentences), vocabulary_size\n",
    "\n",
    "x = np.zeros(shape=x_shape, dtype=np.bool)\n",
    "y = np.zeros(shape=y_shape, dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    y[i,char_to_index[next_chars[i]]] = 1\n",
    "    for j, char in enumerate(sentence):\n",
    "        x[i,j,char_to_index[char]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide on the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 512\n",
    "epochs = 50\n",
    "lstm_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(lstm_size, input_shape=(sentence_length, vocabulary_size)))\n",
    "model.add(Dense(vocabulary_size))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(x, y, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./weights.hdf5')\n",
    "# model.load_weights('./weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the model for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 10 random places in the text to use as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_indices = np.random.choice(len(text) - sentence_length, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide on prediction length and temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_length = 100\n",
    "temperature = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in start_indices:\n",
    "    print('-' * prediction_length)\n",
    "    input_chars = text[i:i+sentence_length]\n",
    "    print('Input:', input_chars)\n",
    "    output_chars = ''\n",
    "    for j in range(prediction_length):\n",
    "        x_predict = np.zeros(shape=(1, sentence_length, vocabulary_size))\n",
    "        for k, char in enumerate(input_chars):\n",
    "            x_predict[0, k, char_to_index[char]] = 1\n",
    "            \n",
    "        probs = model.predict(x_predict, verbose=0)[0]\n",
    "        probs = np.asarray(probs).astype('float64')\n",
    "        probs = np.clip(probs, a_min=1e-32, a_max=None)\n",
    "        not_probs = np.exp(np.log(probs) / temperature)\n",
    "        adjusted_probs = not_probs / np.sum(not_probs)\n",
    "        predicted_index = np.argmax(np.random.multinomial(1, adjusted_probs))\n",
    "        predicted_char = index_to_char[predicted_index]\n",
    "        output_chars += predicted_char\n",
    "        input_chars = input_chars[1:] + predicted_char\n",
    "        \n",
    "    print('Output:', output_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Python module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Juptyer notebook to Python module for production use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see lstm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: setup your local machine for deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Install Anaconda from [here](https://www.anaconda.com/download)\n",
    "1. Install Tensorflow from [here](https://www.tensorflow.org/install/)\n",
    "    - If you have a Windows or Linux computer with a supported NVIDIA GPU you can install Tensorflow with GPU support.\n",
    "        - [Supported GPUs](https://developer.nvidia.com/cuda-gpus)\n",
    "1. Create deep-learning environment by running:\n",
    "    - Windows: `conda env create -f environment_windows.yml`\n",
    "    - Windows GPU: `conda env create -f environment_windows_gpu.yml`\n",
    "    - Linux: `conda env create -f environment_linux.yml`\n",
    "    - Linux GPU: `conda env create -f environment_linux_gpu.yml`\n",
    "    - macOS: `conda env create -f environment_macos.yml`\n",
    "    - macOS GPU: NA (As of version 1.2, TensorFlow no longer provides GPU support on macOS.)\n",
    "1. Activate the environment by running:\n",
    "    - Windows: `activate deep_learning`\n",
    "    - Linux: `source activate deep_learning`\n",
    "    - macOS: `source activate deep_learning`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: setup AWS for deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create [AWS](https://aws.amazon.com) account or login to [AWS](https://aws.amazon.com)\n",
    "1. Review the limits for `p2.xlarge` instances [here](https://console.aws.amazon.com/ec2/v2/home?#Limits)\n",
    "1. If your current limit is 0:\n",
    "    - Click `Request limit increase`\n",
    "    - Fill all the fields in the form:\n",
    "        - For the \"Region\" field, select your prefered region (I recommend US East (Northern Virginia)\n",
    "        - For the \"New limit value\", enter `1` (You will not get more anyway, but your waiting time might be longer)\n",
    "        - For the \"Use Case Description\", enter: \"Studying deep learning with Deep Learning Tribe\"\n",
    "    - Wait up to 48 hours for the limit increase\n",
    "1. Visit [EC2 Management Console](https://console.aws.amazon.com/ec2/v2/home)\n",
    "1. Click `Launch Instance`\n",
    "1. Select `AWS Marketplace` (in the menu on the left)\n",
    "1. Search for `Deep Learning AMI (Ubuntu)`\n",
    "1. Click `Select`\n",
    "1. Click `Continue`\n",
    "1. Select `6. Configure Security Group` (in the menu on top)\n",
    "1. If you don't have a security group with port 8888 open:\n",
    "    - Select `Create a new security group`\n",
    "    - Click `Add Rule`\n",
    "        - Make sure that `Type` is set to `Custom TCP Rule`\n",
    "        - Set `Port Range` to `8888`\n",
    "        - Enter `For running Jupyter on port 8888` in the `Description` field\n",
    "1. Click `Review and Launch`\n",
    "1. Click `Launch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
